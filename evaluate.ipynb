{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390262a9-da5a-4d39-bb1a-b2ed099882b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.18.0\n",
    "!pip install pandas==1.4.1\n",
    "!pip install numpy==1.22.2\n",
    "!pip install torch==1.8.1\n",
    "!pip install evaluate==0.4.0\n",
    "!pip install bert-score==0.3.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "874b6784-66e6-4206-952e-c6b7685944c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from transformers import set_seed\n",
    "from evaluate import load\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import transformers \n",
    "import numpy as np\n",
    "import bert_score\n",
    "import evaluate\n",
    "import logging\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6c18e1-fed8-4e64-89b8-0720e7bed7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(123)\n",
    "np.random.seed(123)\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c34f35-6c09-4b35-9175-30648c023db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BOS_TOKEN = '<|startoftext|>'\n",
    "EOS_TOKEN = '<|endoftext|>'\n",
    "PAD_TOKEN = '<|pad|>'\n",
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9d2dd4-cb21-42ef-9019-1c1ea3dadfa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bertscore = load('bertscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "004f4fe3-b555-4a92-9b81-d5bba1128907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Custom Tokenizer: PreTrainedTokenizer(name_or_path='../01-tokenize/vocab-custom', vocab_size=50257, model_max_len=128, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<|pad|>'})\n"
     ]
    }
   ],
   "source": [
    "custom_tokenizer = GPT2Tokenizer.from_pretrained('../01-tokenize/vocab-custom', \n",
    "                                                 bos_token=BOS_TOKEN, \n",
    "                                                 eos_token=EOS_TOKEN, \n",
    "                                                 pad_token=PAD_TOKEN, \n",
    "                                                 lower=True,\n",
    "                                                 return_tensors='pt')\n",
    "custom_tokenizer.padding_side = 'left'\n",
    "custom_tokenizer.model_max_length = MAX_LEN\n",
    "logger.info(f'Custom Tokenizer: {custom_tokenizer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b04e90f7-039e-49ca-8b64-e6c758c2c0a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_model = transformers.AutoModelForCausalLM.from_pretrained('.././02-finetune/model/custom-finetuned')\n",
    "_ = custom_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e2eb4f0-3220-4065-bf3d-93ec3d1e3a47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    681\n",
       "answer      681\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('.././01-tokenize/data/faq_test.csv')\n",
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3652b64a-77ed-445a-ad5d-691118362c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(question: str, ground_truth: str, tokenizer: GPT2Tokenizer, model: transformers.AutoModelForCausalLM) -> str:\n",
    "    # create a prompt in compliance with the one used during training without the answer part\n",
    "    prompt = f'{BOS_TOKEN}question: {question}\\nanswer:'\n",
    "    # generate tokens\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "    # predict response (answer)\n",
    "    gt_len = len(question.split()) + len(ground_truth.split()) + 1\n",
    "    response = model.generate(input_ids, \n",
    "                              do_sample=True, \n",
    "                              top_k=1, \n",
    "                              min_new_tokens=gt_len,\n",
    "                              max_new_tokens=gt_len,\n",
    "                              repetition_penalty=10.0,\n",
    "                              length_penalty=-0.1,\n",
    "                              pad_token_id=tokenizer.eos_token_id,\n",
    "                              eos_token_id=-1,\n",
    "                              top_p=1.0)\n",
    "    # decode the predicted tokens into texts\n",
    "    response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "    answer = response_text.split('answer: ')[-1]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af308171-19ed-4141-b87f-2837ec95796f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "681it [45:34,  4.01s/it]\n"
     ]
    }
   ],
   "source": [
    "custom_gpt2_answers = []\n",
    "\n",
    "for _, row in tqdm(test_df.iterrows()):\n",
    "    question, ground_truth = row\n",
    "    answer = predict(question, ground_truth, custom_tokenizer, custom_model)\n",
    "    custom_gpt2_answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed82cc54-5b84-49e3-93b6-a910caf41900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_score_custom_gpt2 = bertscore.compute(predictions=custom_gpt2_answers, references=test_df['answer'].to_list(), lang='en')['f1']\n",
    "    \n",
    "test_df['custom_gpt2_answer'] = custom_gpt2_answers\n",
    "\n",
    "test_df['bert_score_custom_gpt2'] = bert_score_custom_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb45291c-0054-4025-b8b1-4a214ba9e355",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83358783308805"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_df['bert_score_custom_gpt2'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
